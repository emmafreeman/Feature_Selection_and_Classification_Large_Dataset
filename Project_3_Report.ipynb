{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project 3: Feature Selection and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Goal: use machine learning techniques to identify important features in order to reduce large dataset, and then build a predictive model for the entire dataset based on this subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 1. Pulled in three subsets of the data:\n",
    "    \n",
    "1. 0.1% of dataset (220 rows). Query time = 2.7 seconds. Memory usage = 8.4 MB.    \n",
    "  \n",
    "2. 0.5% of dataset (500 rows). Query time = 6.2 seconds. Memory usage = 19.1 MB.    \n",
    "  \n",
    "3. Used ANOVA (f_classif) to find the features that are the least important (have the highest p-values) across all subsets. Pulled subsets of 1000 rows at a time, dropped the 4,500 features/columns with the highest p-values, and merged them into a dataframe of 20,000 rows and 500 columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 2.\n",
    "## Built a pipeline to perform a naive logistic regression as a baseline model (using GridSearchCV for cross-validation), with a high C-value for minimal regularization. \n",
    "## Built three feature selection pipelines.\n",
    "## Chose the best of those three pipelines, and applied it to a GridSearched Logistic Regression to tune the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline 0: GridSearchCV on a naive (empty param grid) Logistic Regression as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logreg = GridSearchCV(LogisticRegression(C=1E10, random_state=42), param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline 1: GridSearchCV on StandardScaler, SelectFromModel(Lasso), LogisticRegression(C=1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe_1_for_gs = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('sfm', SelectFromModel(Lasso())), \n",
    "    ('lr', LogisticRegression(C=1E10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {'sfm__estimator':[Lasso(alpha=.01), RandomForestClassifier()]\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gs_pipe_1 = GridSearchCV(pipe_1_for_gs, \n",
    "                         params, \n",
    "                         cv=StratifiedShuffleSplit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline 2: GridSearchCV on StandardScaler, SelectPercentile, LogisticRegression(C=1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe_2_for_gs = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('anova', SelectPercentile()), \n",
    "    ('lr', LogisticRegression(C=1E10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {'anova__percentile': [1,3,10,15,30]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "    gs_pipe_2.best_estimator_\n",
    "\n",
    "    Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('anova', SelectPercentile(percentile=3,\n",
    "             score_func=<function f_classif at 0x7fc82ea39840>)), ('lr', LogisticRegression(C=10000000000.0, class_weight=None, dual=False,\n",
    "              fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "              multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "              solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline 3: GridSearchCV on StandardScaler, SelectKBest, RandomForestClassifier, LogisticRegression(C=1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe_3_for_gs = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('skb', SelectKBest()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('lr', LogisticRegression(C=1E10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {'rf__n_estimators': [3,5,10,12,15,30],\n",
    "    'skb__k': [2,6,10,14,20] # k should correspond to what we know about the data and how many important features!\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gs_pipe_3 = GridSearchCV(pipe_3_for_gs,\n",
    "                         params,\n",
    "                         cv=StratifiedShuffleSplit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('skb', SelectKBest(k=14, score_func=<function f_classif at 0x7f5439cad6a8>)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nod...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_3.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline 4: use parameters from the best Pipeline to tune the model\n",
    "### GridSearchCV on StandardScaler, SelectPercentile, LogisticRegression, to find best values for LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('anova', SelectPercentile(percentile=15)), \n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__C': [0.01, .1, 1, 10, 25, 50, 75, 100, 1E3, 1E4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gspipe = GridSearchCV(best_pipe,\n",
    "                      params,\n",
    "                      cv=StratifiedShuffleSplit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "best params: lr_C=100, lr_penalty = l1  \n",
    "second-best params: lr_C=0.01, lr_penalty = l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('Project3Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data subset</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>fit time</th>\n",
       "      <th>pipeline_memory usage</th>\n",
       "      <th>query time</th>\n",
       "      <th>data_memory usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.26</td>\n",
       "      <td>500 bytes</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.4 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.1 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.12</td>\n",
       "      <td>500 bytes</td>\n",
       "      <td>6.2</td>\n",
       "      <td>19.1 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.1 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>5.12</td>\n",
       "      <td>500 bytes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.1 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.81</td>\n",
       "      <td>16.8 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11.7 KB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data subset  pipeline  train score  test score  fit time  \\\n",
       "0             1         0         1.00        0.59      0.26   \n",
       "1             1         1         1.00        0.58      0.08   \n",
       "2             1         2         1.00        0.65      0.04   \n",
       "3             1         3         0.77        0.60      0.06   \n",
       "4             1         4         1.00        0.62      0.04   \n",
       "5             2         0         1.00        0.52      1.12   \n",
       "6             2         1         1.00        0.53      0.19   \n",
       "7             2         2         1.00        0.53      0.14   \n",
       "8             2         3         0.56        0.52      0.08   \n",
       "9             2         4         1.00        0.56      0.10   \n",
       "10            3         0         0.58        0.51      5.12   \n",
       "11            3         1         0.53        0.51      0.53   \n",
       "12            3         2         0.52        0.52      0.47   \n",
       "13            3         3         0.53        0.52      2.81   \n",
       "14            3         4         0.55        0.52      0.64   \n",
       "\n",
       "   pipeline_memory usage  query time data_memory usage  \n",
       "0              500 bytes         2.7            8.4 MB  \n",
       "1                 1.1 KB         NaN               NaN  \n",
       "2                 2.7 KB         NaN               NaN  \n",
       "3                 2.7 KB         NaN               NaN  \n",
       "4                11.7 KB         NaN               NaN  \n",
       "5              500 bytes         6.2           19.1 MB  \n",
       "6                 1.1 KB         NaN               NaN  \n",
       "7                 2.7 KB         NaN               NaN  \n",
       "8                 2.7 KB         NaN               NaN  \n",
       "9                11.7 KB         NaN               NaN  \n",
       "10             500 bytes         NaN               NaN  \n",
       "11                1.1 KB         NaN               NaN  \n",
       "12                2.7 KB         NaN               NaN  \n",
       "13               16.8 KB         NaN               NaN  \n",
       "14               11.7 KB         NaN               NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Interesting: the training scores dropped significantly when I pulled in more data, but the test scores only dropped slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Next steps: check final shape of data after transformations; see what features (columns) get kept and if they're the same each time. Would mean we only have to pull those features to use for predictions. Document (system architecture) engineering stuff (AWS, sklearn, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feedback: 1) how to explore the feature selection that occurred and what it means? 2) did tuning the logistic regression in the final step actually do anything? (scores didn't improve) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
